## Optimizers
- [Variants of Gradient Descent](http://ruder.io/optimizing-gradient-descent/)
## Regularization
 - [L1  (lasso) for dummies](https://medium.com/mlreview/l1-norm-regularization-and-sparsity-explained-for-dummies-5b0e4be3938a)

## Loss Functions

 - [Cross Entropy, KL Divergence](http://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/) 
 - [KL Divergence Forward and Reverse](https://wiseodd.github.io/techblog/2016/12/21/forward-reverse-kl/)

## Miscellaneous 
- [Monte Carlo Approximation](https://theclevermachine.wordpress.com/2012/09/22/monte-carlo-approximations/)
